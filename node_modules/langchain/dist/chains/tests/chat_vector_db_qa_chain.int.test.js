"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const globals_1 = require("@jest/globals");
const openai_1 = require("../../llms/openai");
const prompts_1 = require("../../prompts");
const llm_chain_1 = require("../llm_chain");
const combine_docs_chain_1 = require("../combine_docs_chain");
const chat_vector_db_chain_1 = require("../chat_vector_db_chain");
const hnswlib_1 = require("../../vectorstores/hnswlib");
const embeddings_1 = require("../../embeddings");
(0, globals_1.test)("Test ChatVectorDBQAChain", async () => {
    const model = new openai_1.OpenAI({});
    const prompt = prompts_1.PromptTemplate.fromTemplate("Print {question}, and ignore {chat_history}");
    const vectorStore = await hnswlib_1.HNSWLib.fromTexts(["Hello world", "Bye bye", "hello nice world", "bye", "hi"], [{ id: 2 }, { id: 1 }, { id: 3 }, { id: 4 }, { id: 5 }], new embeddings_1.OpenAIEmbeddings());
    const llmChain = new llm_chain_1.LLMChain({ prompt, llm: model });
    const combineDocsChain = new combine_docs_chain_1.StuffDocumentsChain({
        llmChain,
        documentVariableName: "foo",
    });
    const chain = new chat_vector_db_chain_1.ChatVectorDBQAChain({
        combineDocumentsChain: combineDocsChain,
        vectorstore: vectorStore,
        questionGeneratorChain: llmChain,
    });
    const res = await chain.call({ question: "foo", chat_history: "bar" });
    console.log({ res });
});
(0, globals_1.test)("Test ChatVectorDBQAChain from LLM", async () => {
    const model = new openai_1.OpenAI({});
    const vectorStore = await hnswlib_1.HNSWLib.fromTexts(["Hello world", "Bye bye", "hello nice world", "bye", "hi"], [{ id: 2 }, { id: 1 }, { id: 3 }, { id: 4 }, { id: 5 }], new embeddings_1.OpenAIEmbeddings());
    const chain = chat_vector_db_chain_1.ChatVectorDBQAChain.fromLLM(model, vectorStore);
    const res = await chain.call({ question: "foo", chat_history: "bar" });
    console.log({ res });
});
//# sourceMappingURL=chat_vector_db_qa_chain.int.test.js.map