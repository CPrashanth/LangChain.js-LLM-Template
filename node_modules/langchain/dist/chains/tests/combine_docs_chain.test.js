"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const globals_1 = require("@jest/globals");
const document_1 = require("../../document");
const llms_1 = require("../../llms");
const load_1 = require("../question_answering/load");
(0, globals_1.test)("Test MapReduceDocumentsChain", async () => {
    let nrMapCalls = 0;
    let nrReduceCalls = 0;
    class FakeLLM extends llms_1.BaseLLM {
        _llmType() {
            return "fake";
        }
        async _generate(prompts, _) {
            return {
                generations: prompts.map((prompt) => {
                    let completion = "";
                    if (prompt.startsWith("Use the following portion")) {
                        nrMapCalls += 1;
                        completion = "a portion of context";
                    }
                    else if (prompt.startsWith("Given the following extracted")) {
                        nrReduceCalls += 1;
                        completion = "a final answer";
                    }
                    return [
                        {
                            text: completion,
                            score: 0,
                        },
                    ];
                }),
            };
        }
    }
    const model = new FakeLLM({});
    const chain = (0, load_1.loadQAChain)(model, { type: "map_reduce" });
    const docs = [
        new document_1.Document({ pageContent: "harrison went to harvard" }),
        new document_1.Document({ pageContent: "ankush went to princeton" }),
    ];
    const res = await chain.call({
        input_documents: docs,
        question: "Where did harrison go to college",
    });
    console.log({ res });
    (0, globals_1.expect)(res).toEqual({
        text: "a final answer",
    });
    (0, globals_1.expect)(nrMapCalls).toBe(0); // below maxTokens
    (0, globals_1.expect)(nrReduceCalls).toBe(1);
});
//# sourceMappingURL=combine_docs_chain.test.js.map